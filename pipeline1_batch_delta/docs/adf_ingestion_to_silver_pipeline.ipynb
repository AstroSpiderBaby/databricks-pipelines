{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df91de85-681e-4f03-b8e4-bcf4c23d34ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # üìò ADF Ingestion to Silver Pipeline\n",
    "# MAGIC **Author:** Bruce Jenks  \n",
    "# MAGIC **Last Updated:** July 7, 2025  \n",
    "# MAGIC  \n",
    "# MAGIC This document outlines the process of using **Azure Data Factory (ADF)** to trigger a data pipeline that moves data into **Azure Data Lake**, followed by transformation and promotion into the **Silver layer in Delta Lake** via Databricks.  \n",
    "# MAGIC  \n",
    "# MAGIC ---\n",
    "# MAGIC \n",
    "# MAGIC ## üîÅ Overview of the ADF to Databricks Flow\n",
    "# MAGIC \n",
    "# MAGIC 1. **ADF Pipeline Execution**\n",
    "# MAGIC     - Triggers when a file lands in blob storage (raw or external container).\n",
    "# MAGIC     - Moves or transforms the file and places it in the **`adf-silver`** container.\n",
    "# MAGIC \n",
    "# MAGIC 2. **Databricks Pipeline**\n",
    "# MAGIC     - Reads the file from `/mnt/adf-silver/Your_Folder`\n",
    "# MAGIC     - Converts it from Parquet (or CSV) to **Delta format**\n",
    "# MAGIC     - Writes to `/mnt/delta/silver/your_table_name`\n",
    "# MAGIC     - Optionally registers the table to Unity Catalog/Hive Metastore\n",
    "# MAGIC \n",
    "# MAGIC ---\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üì• ADF Setup Notes\n",
    "# MAGIC - **Linked Services:** Azure Blob Storage & Databricks\n",
    "# MAGIC - **Dataset Format:** Parquet or CSV from ADF\n",
    "# MAGIC - **Sink Path:** `https://datalakelv426.blob.core.windows.net/adf-silver/<your-folder>`\n",
    "# MAGIC - **Debugging:** Use `Display Output` in ADF to confirm destination path.\n",
    "# MAGIC \n",
    "# MAGIC ‚úÖ **Tip:** Use `\"@dataset().path\"` + `\"@utcnow()\"` to dynamically name your output files if needed.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üìÇ Mount Check (optional)\n",
    "# MAGIC Confirm that `/mnt/adf-silver` is mounted and accessible:\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "display(dbutils.fs.ls(\"/mnt/adf-silver\"))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üîÑ Sample Code to Promote to Silver Layer\n",
    "# MAGIC This example reads the file from ADF output and converts it to Delta:\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from write_utils import write_df_to_delta  # already in repo\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "input_path = \"/mnt/adf-silver/Vendor_Registry_Silver\"  # From ADF\n",
    "output_path = \"/mnt/delta/silver/vendor_registry_silver\"  # Delta Silver\n",
    "\n",
    "df = spark.read.format(\"parquet\").load(input_path)\n",
    "\n",
    "write_df_to_delta(\n",
    "    df,\n",
    "    path=output_path,\n",
    "    mode=\"overwrite\",\n",
    "    merge_schema=True,\n",
    "    register_table=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üß™ Validation\n",
    "# MAGIC After loading to Delta, validate the table exists:\n",
    "# MAGIC \n",
    "# MAGIC ```sql\n",
    "# MAGIC SELECT * FROM vendor_registry_silver LIMIT 10\n",
    "# MAGIC ```\n",
    "# MAGIC \n",
    "# MAGIC Or confirm with Python:\n",
    "# MAGIC \n",
    "# MAGIC ```python\n",
    "# MAGIC spark.sql(\"SELECT COUNT(*) FROM vendor_registry_silver\").show()\n",
    "# MAGIC ```\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üìù Notes and Gotchas\n",
    "# MAGIC - If the mount isn't working, ensure `secret_scope_setup` or `azure_key_vault_setup` is completed.\n",
    "# MAGIC - Confirm the ADF container and folder name match exactly.\n",
    "# MAGIC - If you get `PATH_NOT_FOUND`, double-check your mount and blob location in Azure Portal.\n",
    "# MAGIC - You can always explore blobs using:\n",
    "# MAGIC   ```python\n",
    "# MAGIC   display(dbutils.fs.ls(\"/mnt/adf-silver\"))\n",
    "# MAGIC   ```\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## üìå Summary\n",
    "# MAGIC - ADF loads data into blob storage under `adf-silver`\n",
    "# MAGIC - Databricks reads and transforms it to Delta format\n",
    "# MAGIC - Silver layer stored at `/mnt/delta/silver/...`\n",
    "# MAGIC - Registered to metastore for SQL-based exploration and BI access\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "adf_ingestion_to_silver_pipeline",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
