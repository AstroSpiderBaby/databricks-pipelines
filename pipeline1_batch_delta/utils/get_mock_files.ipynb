{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9519cd9b-4573-4fec-a5ba-07b4988ade00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Destination directory (downloadable)\n",
    "target_dir = \"/dbfs/FileStore/mock_data/\"\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Define sources and how to read/export each\n",
    "def export_csv_from_dbfs(dbfs_path, file_name):\n",
    "    full_path = f\"/dbfs{dbfs_path}\"\n",
    "    if os.path.exists(full_path):\n",
    "        df = pd.read_csv(full_path)\n",
    "        df.to_csv(f\"{target_dir}{file_name}\", index=False)\n",
    "        print(f\"‚úÖ Exported: {file_name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found: {dbfs_path}\")\n",
    "\n",
    "def export_json_from_dbfs(dbfs_path, file_name):\n",
    "    full_path = f\"/dbfs{dbfs_path}\"\n",
    "    if os.path.exists(full_path):\n",
    "        df = pd.read_json(full_path)\n",
    "        df.to_json(f\"{target_dir}{file_name}\", orient=\"records\", indent=2)\n",
    "        print(f\"‚úÖ Exported: {file_name}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Not found: {dbfs_path}\")\n",
    "\n",
    "def export_from_delta(delta_path, file_name):\n",
    "    df = spark.read.format(\"delta\").load(delta_path)\n",
    "    df.limit(100).toPandas().to_csv(f\"{target_dir}{file_name}\", index=False)\n",
    "    print(f\"‚úÖ Exported from Delta: {file_name}\")\n",
    "\n",
    "\n",
    "# Export all mock files\n",
    "export_csv_from_dbfs(\"/FileStore/pipeline1_batch_delta/moc_source_a/Inventory.csv\", \"inventory.csv\")\n",
    "export_csv_from_dbfs(\"/FileStore/pipeline1_batch_delta/moc_source_b/Shipments.csv\", \"shipments.csv\")\n",
    "export_csv_from_dbfs(\"/FileStore/pipeline1_batch_delta/moc_source_c/Vendors.csv\", \"vendors.csv\")\n",
    "export_csv_from_dbfs(\"/mnt/raw-ingest/finance_invoice_data.csv\", \"finance_invoice_data.csv\")\n",
    "\n",
    "export_json_from_dbfs(\"/mnt/external-ingest/web_form_submissions.json\", \"web_forms.json\")\n",
    "\n",
    "export_from_delta(\"/mnt/delta/bronze/vendor_compliance\", \"vendor_compliance.csv\")\n",
    "\n",
    "print(\"\\nüìÅ All mock data files saved to: /dbfs/FileStore/mock_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a9fcb20-4d61-4850-8cc2-5146950e44da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "databricks fs cp dbfs:/FileStore/mock_data/finance_invoice_data.csv ./mock_data/finance_invoice_data.csv\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "get_mock_files",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
