{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952c8f0a-3a1e-4df7-92a4-2f8250199dd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_date, upper, trim, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType, IntegerType\n",
    "from pyspark.sql.types import BooleanType\n",
    "# Load Bronze data\n",
    "df = spark.read.format(\"delta\").load(\"/mnt/delta/bronze/finance_invoices\")\n",
    "\n",
    "# Clean and enrich\n",
    "df_clean = (\n",
    "    df.withColumn(\"vendor\", upper(trim(col(\"vendor\"))))\n",
    "      .withColumn(\"invoice_date\", to_date(col(\"invoice_date\")))\n",
    "      .withColumn(\"due_date\", to_date(col(\"due_date\")))\n",
    "      .withColumn(\"paid_flag\", when(col(\"paid\") == \"Yes\", True).otherwise(False))\n",
    "      .drop(\"paid\")\n",
    ")\n",
    "\n",
    "# Drop nulls from key fields\n",
    "df_clean = df_clean.dropna(subset=[\"invoice_id\", \"vendor\", \"amount_usd\"])\n",
    "\n",
    "# Enforce schema explicitly (optional but good for pipeline consistency)\n",
    "schema = StructType([\n",
    "    StructField(\"invoice_id\", StringType(), False),\n",
    "    StructField(\"vendor\", StringType(), False),\n",
    "    StructField(\"amount_usd\", DoubleType(), False),\n",
    "    StructField(\"invoice_date\", DateType(), True),\n",
    "    StructField(\"due_date\", DateType(), True),\n",
    "    StructField(\"paid_flag\", BooleanType(), True),\n",
    "    StructField(\"source_file\", StringType(), True),\n",
    "    StructField(\"ingestion_type\", StringType(), True),\n",
    "])\n",
    "# Apply schema explicitly\n",
    "df_clean = spark.createDataFrame(df_clean.rdd, schema=schema)\n",
    "\n",
    "# Clean up existing location (if needed)\n",
    "import shutil\n",
    "dbutils.fs.rm(\"dbfs:/mnt/delta/silver/finance_invoices\", recurse=True)\n",
    "from pyspark.sql.functions import col, to_date, upper, trim, when\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, DateType, IntegerType\n",
    "\n",
    "# Load Bronze\n",
    "df = spark.read.format(\"delta\").load(\"/mnt/delta/bronze/finance_invoices\")\n",
    "\n",
    "# Clean and enrich\n",
    "df_clean = (\n",
    "    df.withColumn(\"vendor\", upper(trim(col(\"vendor\"))))\n",
    "      .withColumn(\"invoice_date\", to_date(col(\"invoice_date\")))\n",
    "      .withColumn(\"due_date\", to_date(col(\"due_date\")))\n",
    "      .withColumn(\"paid_flag\", when(col(\"paid\") == \"Yes\", 1).otherwise(0))\n",
    "      .drop(\"paid\")\n",
    ")\n",
    "\n",
    "# Drop nulls from key fields\n",
    "df_clean = df_clean.dropna(subset=[\"invoice_id\", \"vendor\", \"amount_usd\"])\n",
    "\n",
    "# üîç Remove bad rows from paid_flag (only keep if numeric or 0/1)\n",
    "df_clean = df_clean.filter(col(\"paid_flag\").isin(0, 1))\n",
    "\n",
    "df_clean.filter(\"invoice_date IS NULL\").count()\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"invoice_id\", StringType(), False),\n",
    "    StructField(\"vendor\", StringType(), False),\n",
    "    StructField(\"amount_usd\", DoubleType(), False),\n",
    "    StructField(\"invoice_date\", DateType(), True),\n",
    "    StructField(\"due_date\", DateType(), True),\n",
    "    StructField(\"paid_flag\", IntegerType(), True),\n",
    "    StructField(\"source_file\", StringType(), True),\n",
    "    StructField(\"ingestion_type\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Apply schema\n",
    "df_clean = spark.createDataFrame(df_clean.rdd, schema=schema)\n",
    "\n",
    "\n",
    "# Optional: Clean up the destination to ensure no conflict\n",
    "dbutils.fs.rm(\"dbfs:/mnt/delta/silver/finance_invoices_v2\", recurse=True)\n",
    "\n",
    "# Write cleanly\n",
    "try:\n",
    "    df_clean.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"overwriteSchema\", \"true\") \\\n",
    "        .partitionBy(\"invoice_date\") \\\n",
    "        .save(\"dbfs:/mnt/delta/silver/finance_invoices_v2\")\n",
    "    print(\"‚úÖ Write successful.\")\n",
    "except Exception as e:\n",
    "    print(\"‚ùå Write failed:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0497d6bc-2017-41fa-8413-1783a517b459",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Optional: Clean up the destination to ensure no conflict\n",
    "dbutils.fs.rm(\"dbfs:/mnt/delta/silver/finance_invoices_v2\", recurse=True)\n",
    "\n",
    "# Write cleanly\n",
    "df.write.format(\"delta\") \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .option(\"overwriteSchema\", \"true\") \\\n",
    "  .partitionBy(\"invoice_date\") \\\n",
    "  .save(\"dbfs:/mnt/delta/silver/finance_invoices_v2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a34d00e9-43a5-485a-ac10-4ea387b5d97a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"delta\").load(\"/mnt/delta/bronze/finance_invoices\")\n",
    "\n",
    "df = df.withColumn(\"invoice_date\", to_date(col(\"invoice_date\")))\n",
    "\n",
    "df.filter(\"invoice_date IS NULL\").show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "transform_finance_invoices.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
