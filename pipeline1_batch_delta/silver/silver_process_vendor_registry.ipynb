{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f0e2d6e5-a9ba-4564-b826-387dc71c28cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def process_vendor_registry(\n",
    "    spark,\n",
    "    source_path: str = \"/mnt/raw-ingest/vendor_data.csv\",\n",
    "    target_path: str = \"/mnt/delta/silver/vendor_registry\",\n",
    "    unique_cols: list = [\"vendor_id\", \"vendor_name\"],\n",
    "    partition_cols: list = [\"vendor_type\"],  # optional\n",
    "    verbose: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads vendor data from raw ingest, optionally transforms, and performs upsert to Delta Lake.\n",
    "\n",
    "    Parameters:\n",
    "    - spark: Active SparkSession\n",
    "    - source_path (str): Path to the raw CSV or Bronze Delta table\n",
    "    - target_path (str): Path to write the Silver-level Delta table\n",
    "    - unique_cols (list): List of columns used as unique keys for upsert\n",
    "    - partition_cols (list): Columns to partition by (optional)\n",
    "    - verbose (bool): Enable detailed logging\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"ðŸ“¥ Reading vendor data from: {source_path}\")\n",
    "\n",
    "    df_raw = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .csv(source_path)\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ðŸ“Š Raw Schema:\")\n",
    "        df_raw.printSchema()\n",
    "\n",
    "    # Placeholder for any transformation logic\n",
    "    transformed_df = df_raw  # <- Modify this if you plan to clean/transform\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ðŸš€ Running upsert_with_hashstring to Silver Delta Table...\")\n",
    "\n",
    "    upsert_with_hashstring(\n",
    "        spark=spark,\n",
    "        df=transformed_df,\n",
    "        target_path=target_path,\n",
    "        unique_cols=unique_cols,\n",
    "        partition_cols=partition_cols,\n",
    "        verbose=verbose\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_process_vendor_registry",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
